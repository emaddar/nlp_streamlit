{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute '_flat_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflair\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m SequenceTagger\n\u001b[1;32m      6\u001b[0m \u001b[39m# load tagger\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m tagger \u001b[39m=\u001b[39m SequenceTagger\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mflair/ner-french\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m sentence \u001b[39m=\u001b[39m Sentence(example)\n\u001b[1;32m     11\u001b[0m \u001b[39m# predict NER tags\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/flair/models/sequence_tagger_model.py:1034\u001b[0m, in \u001b[0;36mSequenceTagger.load\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1031\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mcls\u001b[39m, model_path: Union[\u001b[39mstr\u001b[39m, Path, Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSequenceTagger\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m cast\n\u001b[0;32m-> 1034\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\u001b[39m\"\u001b[39m\u001b[39mSequenceTagger\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mload(model_path\u001b[39m=\u001b[39;49mmodel_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/flair/nn/model.py:559\u001b[0m, in \u001b[0;36mClassifier.load\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    556\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mcls\u001b[39m, model_path: Union[\u001b[39mstr\u001b[39m, Path, Dict[\u001b[39mstr\u001b[39m, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mClassifier\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    557\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m cast\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\u001b[39m\"\u001b[39m\u001b[39mClassifier\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mload(model_path\u001b[39m=\u001b[39;49mmodel_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/flair/nn/model.py:191\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_path, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    190\u001b[0m     model_file \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_fetch_model(\u001b[39mstr\u001b[39m(model_path))\n\u001b[0;32m--> 191\u001b[0m     state \u001b[39m=\u001b[39m load_torch_state(model_file)\n\u001b[1;32m    192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     state \u001b[39m=\u001b[39m model_path\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/flair/file_utils.py:355\u001b[0m, in \u001b[0;36mload_torch_state\u001b[0;34m(model_file)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m# load_big_file is a workaround byhttps://github.com/highway11git\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m# to load models on some Mac/Windows setups\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[39m# see https://github.com/zalandoresearch/flair/issues/351\u001b[39;00m\n\u001b[1;32m    354\u001b[0m f \u001b[39m=\u001b[39m load_big_file(model_file)\n\u001b[0;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(f, map_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    814\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 815\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/serialization.py:1043\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1041\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1042\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1043\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1045\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1047\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/rnn.py:325\u001b[0m, in \u001b[0;36mRNNBase.__setstate__\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights_names\u001b[39m.\u001b[39mextend(weights[:\u001b[39m2\u001b[39m])\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights \u001b[39m=\u001b[39m [\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, wn) \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, wn) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m                           \u001b[39mfor\u001b[39;00m wn \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights_names]\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weight_refs \u001b[39m=\u001b[39m [weakref\u001b[39m.\u001b[39mref(w) \u001b[39mif\u001b[39;00m w \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m                           \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights]\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LSTM' object has no attribute '_flat_weights'"
     ]
    }
   ],
   "source": [
    "\n",
    "example = \"Bonjour, je m'appelle Emad et j'ahbit Ã  Paris\"\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-french\")\n",
    "\n",
    "sentence = Sentence(example)\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence\n",
    "print(sentence)\n",
    "\n",
    "# print predicted NER spans\n",
    "print('The following NER tags are found:')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score  index    word  start  end entity\n",
      "0  0.999105      5   Sarah     17   22    PER\n",
      "1  0.999755     10  Canada     36   42    LOC\n",
      "2  0.998341     14   Ahmad     58   63    PER\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PER</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PER</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>0.998341</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity    word     score  index  start  end\n",
       "0    PER   Sarah  0.999105      5     17   22\n",
       "1    LOC  Canada  0.999755     10     36   42\n",
       "2    PER   Ahmad  0.998341     14     58   63"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  entity  count\n",
      "0    LOC      1\n",
      "1    PER      2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print resulting dataframe\n",
    "print(count_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3f62de1b302f64c2831ea713a401a84c2f2d558920bd33562ff2faff39b3e74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
